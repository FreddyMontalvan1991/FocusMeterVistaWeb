import cv2
from fastapi import FastAPI, Response
from ultralytics import YOLO
import threading
import time

app = FastAPI()

# --- CONFIGURACI√ìN ---
MODEL_PATH = "app/extras/best.pt"
model = YOLO(MODEL_PATH)

# Variables Globales en RAM
ultima_imagen = None
datos_estado = {"nivel": 0, "total": 0, "camara": "Buscando..."}

def detectar_mejor_camara():
    """
    Escanea √≠ndices del 1 al 5 para USB, y cae al 0 para integrada.
    """
    print("üîç Escaneando puertos de c√°mara...")
    # Intentar c√°maras externas primero (√≠ndices 1 al 5)
    for index in range(1, 6):
        cap = cv2.VideoCapture(index)
        if cap.isOpened():
            ret, frame = cap.read()
            if ret:
                cap.release()
                print(f"‚úÖ C√°mara USB detectada en el √≠ndice: {index}")
                return index
            cap.release()
    
    # Si no, intentar la integrada (0)
    cap = cv2.VideoCapture(0)
    if cap.isOpened():
        print("üíª No se detect√≥ USB. Usando c√°mara integrada (√≠ndice 0).")
        cap.release()
        return 0
    
    print("‚ùå No se encontr√≥ ninguna c√°mara disponible.")
    return None

def bucle_deteccion():
    global ultima_imagen, datos_estado
    
    idx = detectar_mejor_camara()
    if idx is None:
        datos_estado["status"] = "Error: No hay c√°mara"
        return

    cap = cv2.VideoCapture(idx)
    # Ajustes de fluidez
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
    
    datos_estado["camara"] = f"Puerto {idx}"

    print("üöÄ Modelo iniciado y procesando...")

    while True:
        ret, frame = cap.read()
        if not ret:
            print("‚ö†Ô∏è Error al leer fotograma. Reintentando...")
            time.sleep(1)
            continue

        # Inferencia
        results = model(frame, conf=0.5, verbose=False)
        boxes = results[0].boxes
        atentos = 0
        total = len(boxes)

        for box in boxes:
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            label = model.names[int(box.cls[0])]
            
            # L√≥gica de color seg√∫n tu modelo
            if label.lower() in ["atento", "attentive"]:
                color, atentos = (0, 255, 0), atentos + 1
            else:
                color = (0, 0, 255)
            
            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
            cv2.putText(frame, f"{label}", (x1, y1-10), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

        # Actualizar datos en RAM
        nivel = atentos / total if total > 0 else 0
        datos_estado["nivel"] = nivel
        datos_estado["total"] = total

        # Mostrar progreso en la consola del servidor (una sola l√≠nea)
        print(f"Detectando en {datos_estado['camara']} | Personas: {total} | Nivel: {nivel:.2%}", end="\r")

        # Convertir a bytes para Streamlit
        _, buffer = cv2.imencode('.jpg', frame)
        ultima_imagen = buffer.tobytes()

# Iniciar el hilo del modelo autom√°ticamente al arrancar el servidor
threading.Thread(target=bucle_deteccion, daemon=True).start()

@app.get("/video")
async def get_video():
    if ultima_imagen is None:
        return Response(status_code=404)
    return Response(content=ultima_imagen, media_type="image/jpeg")

@app.get("/datos")
async def get_datos():
    return datos_estado

if __name__ == "__main__":
    import uvicorn
    # Iniciamos el servidor
    uvicorn.run(app, host="0.0.0.0", port=8000)